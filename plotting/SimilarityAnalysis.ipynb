{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\devin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, fftfreq, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleRate = 20e6\n",
    "\n",
    "# number of samples per class\n",
    "num_samp_per_class = 10000\n",
    "\n",
    "# FFT size for the STFT operation (which is same as the feature vector size)\n",
    "fft_size = feature_vector_size = 2048 #1024\n",
    "\n",
    "# number of overlapping samples for the STFT operation\n",
    "fft_overlap = 256\n",
    "\n",
    "def getData(cfileName):\n",
    "    \"\"\"\n",
    "    Given a name of a *.cfile, this function extracts the interleaved\n",
    "    Inphase-Quadrature data samples and convert it into a numpy array of complex\n",
    "    data elements. *.cfile format has interleaved I and Q samples where each sample\n",
    "    is a float32 type. GNURadio Companion (GRC) scripts output data into a file\n",
    "    though a file sink block in this format.\n",
    "    Read more in SDR data types: https://github.com/miek/inspectrum\n",
    "    \"\"\"\n",
    "    # Read the *.cfile which has each element in float32 format.\n",
    "    data = np.fromfile(cfileName, dtype=\"float32\")\n",
    "    \n",
    "    # Take each consecutive interleaved I sample and Q sample to create a single complex element.\n",
    "    data = data[0::2] + 1j*data[1::2]\n",
    "    # print(\"data type=\", type(data))\n",
    "    # Return the complex numpy array.\n",
    "    return data\n",
    "\n",
    "def getSegmentData(iqData, offsetTime, windowTime):\n",
    "    '''\n",
    "    Given a I-Q data, an offset value as a time, and an window time,\n",
    "    this function extracts the required segment from the data and return it as\n",
    "    a complx numpy array.    \n",
    "    '''\n",
    "\n",
    "    # Segment starting offset (sample points)\n",
    "    start = offsetTime * sampleRate    \n",
    "    # Segment ending offset (sample points)\n",
    "    end = start + (windowTime * sampleRate)\n",
    "    #print(\"start=%d\", int(start))\n",
    "    #print(\"end=%d\", int(end))\n",
    "    #Return the starting index and ending index\n",
    "    segment = iqData[int(start):int(end)]\n",
    "\n",
    "    #return data\n",
    "    return segment\n",
    "\n",
    "def getTimeDuration(complexData):\n",
    "    '''\n",
    "    Calculate the total time duration represented in complex Numpy array.\n",
    "    '''\n",
    "    # each complex value represents a sample\n",
    "    nSamples = len(complexData)\n",
    "\n",
    "    # nSamples = duration x sample_rate\n",
    "    duration =  nSamples / sampleRate\n",
    "    return duration\n",
    "\n",
    "def getFilePath(type, payload, freq):\n",
    "    if type == \"udp\":\n",
    "        if payload == 1:\n",
    "            flag = \"udp_all_1\"\n",
    "        else:\n",
    "            flag = \"udp_all_0\"\n",
    "    else:\n",
    "        if payload == 1:\n",
    "            flag = \"tcp_all_1\"\n",
    "        else:\n",
    "            flag = \"tcp_all_0\"\n",
    "\n",
    "    filePath = f\"../dataset/10s20MHz/{flag}_freq={freq}.0em_capture.cfile\"\n",
    "    return filePath\n",
    "\n",
    "def loadData(type, payload, freq):\n",
    "    filePath = getFilePath(type, payload, freq)\n",
    "    dataSet = getData(filePath)\n",
    "    print(f\"Loaded {type} all {payload}, {freq}.0MHz\")\n",
    "\n",
    "    return dataSet\n",
    "\n",
    "def loadSegment(type, payload, freq, offset, length):\n",
    "    filePath = getFilePath(type, payload, freq)\n",
    "    \n",
    "    dataSet = getData(filePath)\n",
    "    dataSegment = getSegmentData(dataSet, offset, length)\n",
    "    print(f\"Loaded {type} all {payload}, {freq}.0MHz of {length}s length starting from {offset}s\")\n",
    "    \n",
    "    return dataSegment\n",
    "\n",
    "def plotWaveform(data, show=1, file_name='./wavform.pdf', file_format='pdf'):\n",
    "    \"\"\"\n",
    "    Given a data set as a complex numpy array, this function returns the waveform plot.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    # Plot the waveform of the selected sample range of the numpy data array\n",
    "    #plt.plot(data)\n",
    "    plt.plot(np.abs(data))\n",
    "    #plt.plot(np.real(data))\n",
    "    #plt.plot(np.imag(data))\n",
    "    \n",
    "    if(show==1):\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Save the waveform into a PDF file\n",
    "        plt.savefig(file_name, fotmat=file_format, bbox_inches='tight')\n",
    "        \n",
    "    return 1\n",
    "\n",
    "def plotFFT(data, show=1):\n",
    "    \"\"\"\n",
    "    Given a data set as a complex numpy array, this function returns the FFT plot.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # get the length of the selected data sample range        \n",
    "    N = len(data)\n",
    "    # get the time interval beteween each sample\n",
    "    T = 1.0 / sampleRate\n",
    "    # calculate the FFT of the selected sample range. But the FFT x axis contains data\n",
    "    # in the range from 0 to positive values first and at the end the negative values\n",
    "    # like 0, 1, 2, 3, 4, -4, -3, -2, -1\n",
    "    yf = fft(data)\n",
    "    # get the vector with frequencies of the sample range. But the output contains data\n",
    "    # in the range from 0 to positive values first and at the end the negative values\n",
    "    # like 0, 1, 2, 3, 4, -4, -3, -2, -1\n",
    "    freqs = fftfreq(N, T)\n",
    "    # shift the frequencies to have it zero-centered, e.g., -4, -3, -2, -1, 0, 1, 2, 3, 4\n",
    "    shifted_freqs = fftshift(freqs)\n",
    "    # rearrange the FFT vector to have it zero-centered, e.g., -4, -3, -2, -1, 0, 1, 2, 3, 4\n",
    "    new_yf = np.concatenate((yf[int(N/2):int(N)], yf[0:int(N/2)]))\n",
    "    # plot the FFT vector against the frequencies\n",
    "    plt.plot(shifted_freqs, np.abs(new_yf))    \n",
    "    #print('len(shifted_freqs)=%d' % len(shifted_freqs))    \n",
    "    #print('len(new_yf)=%d' % len(new_yf))    \n",
    "\n",
    "    if(show==1):\n",
    "        plt.show()\n",
    "    else:\n",
    "        # save theFFT plot as a PDF file.\n",
    "        plt.savefig('./fft.pdf', fotmat='pdf', bbox_inches='tight')\n",
    "        \n",
    "    return 1\n",
    "\n",
    "def getFFT(pattern):\n",
    "    _, _, fft_result = signal.stft(pattern, fs=sampleRate, nperseg=fft_size, noverlap=fft_overlap)\n",
    "    return fft_result\n",
    "\n",
    "def computeNormalizedXcor(signalI, signalJ):\n",
    "    normalizedI = (signalI - np.mean(signalI)) / (np.std(signalI))\n",
    "    normalizedJ = (signalJ - np.mean(signalJ)) / (np.std(signalJ))\n",
    "    c = signal.correlate(normalizedI, normalizedJ, mode=\"full\") / max(len(signalI), len(signalJ))\n",
    "    print(\"XCOR\", c)\n",
    "    center = int(len(c)/2)\n",
    "    return (c[center], center, c)\n",
    "\n",
    "\n",
    "def computeXcor(signalI, signalJ):\n",
    "    c = signal.correlate(signalI, signalJ, mode=\"full\") / max(len(signalI), len(signalJ))\n",
    "    center = int(len(c)/2)\n",
    "    return (c[center], center, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tcp all 1, 70.0MHz of 0.1s length starting from 2s\n",
      "Loaded tcp all 0, 70.0MHz of 0.1s length starting from 2s\n"
     ]
    }
   ],
   "source": [
    "offset = 2 #seconds\n",
    "duration = 1e-1 #seconds\n",
    "\n",
    "data1_segment = loadSegment(\"tcp\", 1, 70, offset, duration)\n",
    "data2_segment = loadSegment(\"tcp\", 0, 70, offset, duration)\n",
    "\n",
    "resampleRate = 10e6\n",
    "resampled1 = signal.resample(data1_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "resampled2 = signal.resample(data2_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XCOR [-7.86687970e-07 -2.43264008e-06 -1.08684802e-06 ... -1.08716798e-06\n",
      " -2.43299198e-06 -7.86176026e-07]\n",
      "Value 0.999999875\n",
      "Value2 0.0006831358032226562\n"
     ]
    }
   ],
   "source": [
    "resampled1 = abs(resampled1)\n",
    "resampled2 = abs(resampled2)\n",
    "print(\"Value\", computeNormalizedXcor(resampled1, resampled1)[0])\n",
    "\n",
    "print(\"Value2\", computeXcor(resampled1, resampled2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tcp all 1, 50.0MHz of 0.1s length starting from 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.3602816e-02+0.00000000e+00j,  2.7279407e-02+0.00000000e+00j,\n",
       "         2.7346905e-02+0.00000000e+00j, ...,\n",
       "         2.7281947e-02+0.00000000e+00j,  1.6547674e-02+0.00000000e+00j,\n",
       "         0.0000000e+00+0.00000000e+00j],\n",
       "       [-6.7949798e-03+8.67433287e-03j, -1.3751213e-02-1.03888116e-04j,\n",
       "        -1.3698394e-02+4.45691476e-05j, ...,\n",
       "        -1.3619113e-02-1.87707788e-04j, -9.8130004e-03-7.75561063e-03j,\n",
       "         0.0000000e+00+0.00000000e+00j],\n",
       "       [-5.7974750e-05-5.76792471e-03j,  9.6007883e-05+1.21573488e-04j,\n",
       "         3.4145898e-05+1.97893351e-05j, ...,\n",
       "        -1.7617887e-05+1.31921886e-04j,  2.9507307e-03+4.28707851e-03j,\n",
       "         0.0000000e+00+0.00000000e+00j],\n",
       "       ...,\n",
       "       [ 3.4097062e-05-2.20955393e-04j,  6.6245579e-05-9.40937098e-05j,\n",
       "         9.5215342e-05-1.35852097e-04j, ...,\n",
       "        -5.2980835e-05+8.77966813e-05j,  3.7572513e-04-4.79552895e-04j,\n",
       "         0.0000000e+00+0.00000000e+00j],\n",
       "       [ 2.3827283e-04+3.37191508e-04j,  4.7304481e-04+1.09972825e-05j,\n",
       "         2.2396076e-04+4.94237756e-05j, ...,\n",
       "        -1.2728606e-03+8.54073005e-05j, -1.0818999e-03+8.03197210e-04j,\n",
       "         0.0000000e+00+0.00000000e+00j],\n",
       "       [-5.0277455e-04+0.00000000e+00j, -1.0236724e-03+0.00000000e+00j,\n",
       "        -4.7005730e-04+0.00000000e+00j, ...,\n",
       "         2.6399232e-03+0.00000000e+00j,  1.7575074e-03+0.00000000e+00j,\n",
       "         0.0000000e+00+0.00000000e+00j]], dtype=complex64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1, filePath1 = loadData(\"tcp\", 1, 30)\n",
    "# duration1 = getTimeDuration(filePath1)\n",
    "# print(\"Time duration of the cf ile file: \" + str(duration1) + \" seconds\")\n",
    "\n",
    "# data2, filePath2 = loadData(\"tcp\", 0, 110)\n",
    "# duration2 = getTimeDuration(filePath2) \n",
    "# print(\"Time duration of the cfile file: \" + str(duration2) + \" seconds\")\n",
    "\n",
    "# length = len(data1)\n",
    "# print(\"Number of samples in cfile data segment: \" + str(length))\n",
    "\n",
    "sampleRate = 20e6\n",
    "offset = 2 #seconds\n",
    "duration = 1e-1 #seconds\n",
    "freqs = [e for e in range(30,111,20)]\n",
    "nFreqs = len(freqs)\n",
    "\n",
    "# Initialize a list to store cross-correlation results\n",
    "cross_correlation_results = []\n",
    "\n",
    "# for i in range(nFreqs):\n",
    "#     for j in range(i+1,nFreqs):\n",
    "#         print(freqs[i],freqs[j])\n",
    "#         data1_segment = loadSegment(\"tcp\", 1, freqs[i], offset, duration)\n",
    "#         data2_segment = loadSegment(\"tcp\", 1, freqs[j], offset, duration)\n",
    "\n",
    "#         resampleRate = 10e6\n",
    "#         resampled1 = signal.resample(data1_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "#         resampled2 = signal.resample(data2_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "\n",
    "#         corr = plt.xcorr(abs(resampled1), abs(resampled2), maxlags=None, normed=True)\n",
    "\n",
    "#         corr_values = corr[1]\n",
    "#         print(corr_values[np.argmax(corr_values)])\n",
    "#         cross_correlation_results.append(corr_values[np.argmax(corr_values)])\n",
    "        \n",
    "data1_segment = loadSegment(\"tcp\", 1, 50, offset, duration)\n",
    "resampleRate = 10e6\n",
    "resampled1 = signal.resample(data1_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "getFFT(abs(data1_segment))\n",
    "\n",
    "def getCosineSimilarity(fft_ti, fft_tj):\n",
    "    return 1 - cosine(fft_ti.flatten(), fft_tj.flatten())\n",
    "\n",
    "cosine_similarity = getCosineSimilarity(fftI, fftJ)\n",
    "\n",
    "print(\"Cosine Similarity:\", cosine_similarity)\n",
    "\n",
    "# length1 = len(data1_segment)\n",
    "# print(\"Number of samples in cfile data segment: \" + str(length1))\n",
    "# print(\"Duration1: \", getTimeDuration(data1_segment))\n",
    "# length2 = len(data2_segment)\n",
    "# print(\"Number of samples in cfile data segment: \" + str(length2))\n",
    "# print(\"Duration2: \", getTimeDuration(data2_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(data1_segment))\n",
    "resampleRate = 10e6\n",
    "resampled1 = signal.resample(data1_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "resampled2 = signal.resample(data2_segment, num=int(resampleRate * duration), t=None, axis=0, window=None, domain='time')\n",
    "\n",
    "# print(len(resampled1))\n",
    "sampleRate = resampleRate\n",
    "# print(\"Duration1: \", getTimeDuration(resampled1))\n",
    "\n",
    "corr = plt.xcorr(abs(resampled1), abs(resampled2), maxlags=None, normed=True)\n",
    "\n",
    "# corr_values = corr[1]\n",
    "# print(corr_values[np.argmax(corr_values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94316804\n"
     ]
    }
   ],
   "source": [
    "corr_values = corr[1]\n",
    "print(corr_values[np.argmax(corr_values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 50, 70, 90, 110]\n",
      "30 50\n",
      "30 70\n",
      "30 90\n",
      "30 110\n",
      "50 70\n",
      "50 90\n",
      "50 110\n",
      "70 90\n",
      "70 110\n",
      "90 110\n"
     ]
    }
   ],
   "source": [
    "freqs = [e for e in range(30,111,20)]\n",
    "nFreqs = len(freqs)\n",
    "\n",
    "# Initialize a list to store cross-correlation results\n",
    "cross_correlation_results = []\n",
    "print(freqs)\n",
    "for i in range(nFreqs):\n",
    "    for j in range(i+1,nFreqs):\n",
    "        print(freqs[i],freqs[j])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util Functions 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trimLength = (196031181+197657076)//3\n",
    "print(\"trim lenght\", trimLength)\n",
    "def getMinLength(pattern_i, pattern_j):\n",
    "    minLen = min(len(pattern_i), len(pattern_j), trimLength)\n",
    "    print(f\"minimum length of datasets: {minLen}\")\n",
    "    return minLen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqs = [e for e in range(30,211,20)]\n",
    "# print(freqs)\n",
    "\n",
    "\n",
    "# dataLengths = []\n",
    "\n",
    "\n",
    "# for freq in freqs:\n",
    "#     data = loadData(\"tcp\", 1, freq)\n",
    "#     dataLengths.append(len(data))\n",
    "\n",
    "# for freq in freqs:\n",
    "#     data = loadData(\"tcp\", 0, freq)\n",
    "#     dataLengths.append(len(data))\n",
    "\n",
    "# for freq in freqs:\n",
    "#     data = loadData(\"udp\", 1, freq)\n",
    "#     dataLengths.append(len(data))\n",
    "\n",
    "# for freq in freqs:\n",
    "#     data = loadData(\"udp\", 0, freq)\n",
    "#     dataLengths.append(len(data))\n",
    "\n",
    "# print(min(dataLengths))\n",
    "# print(max(dataLengths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets for trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [e for e in range(30,111,20)]\n",
    "nFreqs = len(freqs)\n",
    "\n",
    "# Initialize a list to store cross-correlation results\n",
    "cross_correlation_results = []\n",
    "\n",
    "# Loop over all pairs of datasets\n",
    "dataSetI = loadData(\"tcp\", 1, 30)\n",
    "dataSetJ = loadData(\"udp\", 1, 110)\n",
    "\n",
    "# Ensure datasets have the same length by truncating the longer dataset\n",
    "# min_length = getMinLength(dataSetI, dataSetJ)\n",
    "\n",
    "# dataSetI = dataSetI[:min_length]\n",
    "# dataSetJ = dataSetJ[:min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = signal.resample(dataSetI, num=10e6, t=None, axis=0, window=None, domain='time')\n",
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using plt.xcorr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-correlation between the datasets\n",
    "corr = plt.xcorr(dataSetI, dataSetJ, maxlags=None, normed=True)\n",
    "\n",
    "corr_values = corr[1]\n",
    "print(corr_values[np.argmax(corr_values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using np.correlate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-correlation between the datasets\n",
    "cross_corr = np.correlate(dataSetI, dataSetJ, mode='full')\n",
    "lags = np.arange(-len(cross_corr) + 1, len(cross_corr))\n",
    "\n",
    "# Plot the cross-correlation data\n",
    "plt.plot(lags, cross_corr)\n",
    "plt.title('Cross-correlation Plot')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Cross-correlation')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding length of dataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [e for e in range(30,111,20)]\n",
    "nFreqs = len(freqs)\n",
    "\n",
    "# Initialize a list to store cross-correlation results\n",
    "cross_correlation_results = []\n",
    "min_length = 0\n",
    "max_length = 0\n",
    "# Loop over all pairs of datasets\n",
    "for i in range(nFreqs):\n",
    "    dataSetI = loadData(\"tcp\", 0, freqs[i])\n",
    "    max_length = max(len(dataSetI), len(dataSetJ), max_length)\n",
    "    print(max_length)\n",
    "    \n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fftI = getFFT(dataSetI)\n",
    "print(fftI.shape)\n",
    "fftJ = getFFT(dataSetJ)\n",
    "print(fftJ.shape)\n",
    "\n",
    "def getCosineSimilarity(fft_ti, fft_tj):\n",
    "    return 1 - cosine(fft_ti.flatten(), fft_tj.flatten())\n",
    "\n",
    "cosine_similarity = getCosineSimilarity(fftI, fftJ)\n",
    "\n",
    "print(\"Cosine Similarity:\", cosine_similarity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
